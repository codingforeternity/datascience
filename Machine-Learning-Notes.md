Email: "projections onto nonlinear subspaces (k-RBMs)" (the email contains hard copies of these papers)
* "Non-Linear Manifolds" - https://www.google.com/search?q=projection+onto+curved+subspaces&ie=utf-8&oe=utf-8#q=projection+onto+nonlinear+subspaces
* RBMs - http://deeplearning.net/tutorial/rbm.html

Email: "restricted boltzman machines, introduction"
* http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/

Email: "Scary machine learning"
* Why You Should be a Little Scared of Machine Learning http://www.reddit.com/r/programming/comments/3l0qek/why_you_should_be_a_little_scared_of_machine/
* This link on Recurrent Neural Networks was linked to from the above: http://karpathy.github.io/2015/05/21/rnn-effectiveness/
  * "RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector"
  * "If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs."
  * "crucially this output vector's contents are influenced not only by the input you just fed in, but also on the entire history of inputs you've fed in in the past."  I.e. this links back to learning in stages (pixels, lines, shapes, faces; or regimes, sectors, instruments).

Email: "What is the difference between convolutional neural networks, restricted Boltzmann machines, and auto-encoders? - Cross Validated"
* http://stats.stackexchange.com/questions/114385/what-is-the-difference-between-convolutional-neural-networks-restricted-boltzma
* "So, if we already had PCA, why the hell did we come up with autoencoders and RBMs? It turns out that PCA only allows linear transformation of a data vectors."

Email: "Restricted Boltzmann machines vs multilayer neural networks - Coursera"
* http://stats.stackexchange.com/questions/40598/restricted-boltzmann-machines-vs-multilayer-neural-networks
* "Once deep (or maybe not that deep) network is pretrained, input vectors are transformed to a better representation and resulting vectors are finally passed to real classifier (such as SVM or logistic regression). In an image above it means that at the very bottom there's one more component that actually does classification."

Coursera Machine Learning Course Notes
* file:///home/fred/Documents/coursera/machine_learning/complete_notes_holehouse/Machine_learning_complete/09_Neural_Networks_Learning.html (from here: http://www.holehouse.org/mlclass/)
* http://cs229.stanford.edu/materials.html
* Email: "octave/matlab resources"
** https://www.coursera.org/learn/machine-learning/supplement/Mlf3e/more-octave-matlab-resources

Email: (no subject)
* Welcome to the AI Conspiracy: The ‘Canadian Mafia’ Behind Tech’s Latest Craze http://recode.net/2015/07/15/ai-conspiracy-the-scientists-behind-deep-learning/
* "Deep-Learning AI Is Taking Over Tech. What Is It?"
* "The results of these collections are then tiled so that they overlap to obtain a better representation of the original image; this is repeated for every such layer. Because of this, they are able to tolerate translation of the input image" https://en.wikipedia.org/wiki/Convolutional_neural_network

Email: "Deep learning to understand..."
* ...anything we don't. Anything we can observe effect and input, but not transmission mechanism.
* E.g. the inner workings of the brain. Which would be very meta, b/c it would be like a machine learning a machine that learns a machine.
* E.g. machine learning to learn the structure of a neural net.  A neural net learning a neural net.  What if it could learn what the outputs and inputs are rather than being programmed to know them.

Email: "The Model Complexity Myth"
* The Model Complexity Myth https://jakevdp.github.io/blog/2015/07/06/model-complexity-myth/
* Gaussian Processes for Machine Learning (free technical book) http://www.gaussianprocess.org/gpml/
* Fill in the Blanks: Using Math to Turn Lo-Res Datasets Into Hi-Res Samples http://www.wired.com/2010/02/ff_algorithm/

Benchmarking Nearest Neighbor Searches in Python
* https://jakevdp.github.io/blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/

https://www.kaggle.com/
