The basic idea is to have a journal that only publishes negative results.  Results are selected for publication based on the quality of the application of the scientific method.

Email: Graveyard database of negative results
* Put them somewhere so they can be studied w/ big data methods
* I.e. somewhere for the data associated with the negative results to go, even if the paper doesn't get published (in JoNR or o/w), even if the research isn't ever finished perhaps we can prevent the data from being abandoned

Email: file under: journal of negative results
* http://marginalrevolution.com/marginalrevolution/2014/01/what-happens-when-we-correct-for-publication-bias.html
  * What happens when we correct for publication bias?
  * by Tyler Cowen on January 31, 2014 at 9:12 am in Data Source, Economics, Science
  * There is a recent paper by Leif D. Nelson, Uri Simonsohn, and Joseph P. Simmons on this topic, the abstract is this:
    > Journals tend to publish only statistically significant evidence, creating a scientific record that markedly overstates the size of effects. We provide a new tool that arrives at unbiased effect size estimates while fully ignoring the unpublished record. It capitalizes on the fact that the distribution of significant p-values, p-curve, is a function of the true underlying effect. Researchers armed with only the sample sizes and p-values of the published findings can fully correct for publication bias. We demonstrate the use of p-curve by reassessing the evidence for the impact of “choice overload” from the Psychology literature, and the impact of minimum wage on unemployment from the Economics literature.
  * When it comes to both the choice overload effect and the minimum wage, correcting for publication bias implies a lack of significance in the overall tenor of the results.  In passing I am not sure the minimum wage is the best example here, since a “no result” paper on that question seems to me entirely publishable these days and indeed for some while.